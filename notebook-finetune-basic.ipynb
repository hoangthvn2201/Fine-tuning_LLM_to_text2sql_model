{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages and model tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T03:30:35.591822Z",
     "iopub.status.busy": "2024-12-27T03:30:35.591491Z",
     "iopub.status.idle": "2024-12-27T03:31:44.707408Z",
     "shell.execute_reply": "2024-12-27T03:31:44.706388Z",
     "shell.execute_reply.started": "2024-12-27T03:30:35.591790Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.47.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.25.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch  --quiet\n",
    "\n",
    "# # Install Hugging Face libraries\n",
    "!pip install  --upgrade transformers datasets accelerate evaluate bitsandbytes --quiet\n",
    "\n",
    "# #FlashAttention only supports Ampere GPUs or newer. #NEED A100 IN GOOGLE COLAB\n",
    "!pip install -U transformers\n",
    "# # !pip install -U flash-attn --no-build-isolation --quiet\n",
    "\n",
    "\n",
    "! pip install peft --quiet\n",
    "! pip install datasets trl ninja packaging --quiet\n",
    "\n",
    "# # Uncomment only if you're using A100 GPU\n",
    "# #!pip install flash-attn --no-build-isolation\n",
    "!pip install diffusers safetensors  --quiet\n",
    "\n",
    "# %pip install -U wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T03:31:44.710154Z",
     "iopub.status.busy": "2024-12-27T03:31:44.709428Z",
     "iopub.status.idle": "2024-12-27T03:32:02.665519Z",
     "shell.execute_reply": "2024-12-27T03:32:02.664630Z",
     "shell.execute_reply.started": "2024-12-27T03:31:44.710114Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    PeftModel,\n",
    "    prepare_model_for_kbit_training,\n",
    "    get_peft_model,\n",
    ")\n",
    "import os, torch, wandb\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from trl import SFTTrainer, setup_chat_format, SFTConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T03:32:20.458466Z",
     "iopub.status.busy": "2024-12-27T03:32:20.457791Z",
     "iopub.status.idle": "2024-12-27T03:32:20.462917Z",
     "shell.execute_reply": "2024-12-27T03:32:20.461944Z",
     "shell.execute_reply.started": "2024-12-27T03:32:20.458434Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "base_model = \"huyhoangt2201/llama-3.2-1b-sql_finetuned_multitableJidouka2_1.0_977_records_mix_fix_210_records_merged\"\n",
    "new_model = \"llama-3.2-1b-sql_finetuned_multitableJidouka2_1.0_977_records_mix_fix_84_records\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T03:32:22.077173Z",
     "iopub.status.busy": "2024-12-27T03:32:22.076376Z",
     "iopub.status.idle": "2024-12-27T03:33:35.281510Z",
     "shell.execute_reply": "2024-12-27T03:33:35.280729Z",
     "shell.execute_reply.started": "2024-12-27T03:32:22.077140Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6f31742e40540c08331607d5fba7b2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/980 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "092fad5705db4b46a727f1f1b9143198",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.47G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a15c4de645d34efa84d53afa44cc526d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/184 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03071741d6294d53926ec12890cee902",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/54.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f911e4d6ead4d17ad2cd02837af43ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7394b2960674485cbb87ea2318c2693a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch_dtype = torch.float16\n",
    "\n",
    "# QLoRA config\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True, bnb_4bit_use_double_quant=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=torch.float16\n",
    ")\n",
    "\n",
    "# Load model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    "\n",
    "    #attn_implementation=attn_implementation\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model,use_fast=True)\n",
    "tokenizer.padding_side = 'right' # to prevent warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T03:48:47.577713Z",
     "iopub.status.busy": "2024-12-27T03:48:47.577342Z",
     "iopub.status.idle": "2024-12-27T03:48:47.794154Z",
     "shell.execute_reply": "2024-12-27T03:48:47.793396Z",
     "shell.execute_reply.started": "2024-12-27T03:48:47.577683Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=['up_proj', 'down_proj', 'gate_proj', 'k_proj', 'q_proj', 'v_proj', 'o_proj']\n",
    ")\n",
    "model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T03:33:35.537932Z",
     "iopub.status.busy": "2024-12-27T03:33:35.537660Z",
     "iopub.status.idle": "2024-12-27T03:33:35.542073Z",
     "shell.execute_reply": "2024-12-27T03:33:35.541195Z",
     "shell.execute_reply.started": "2024-12-27T03:33:35.537906Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T03:33:35.544270Z",
     "iopub.status.busy": "2024-12-27T03:33:35.543728Z",
     "iopub.status.idle": "2024-12-27T03:33:38.757731Z",
     "shell.execute_reply": "2024-12-27T03:33:38.756926Z",
     "shell.execute_reply.started": "2024-12-27T03:33:35.544243Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61a8aed7232f4d7b86352f842d4a2357",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "output84_fixed_errors.csv:   0%|          | 0.00/45.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25745327496c4a1996681b86ae9c99ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/84 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2793875a58ca4c2b93c2d0fd5205b803",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/80 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e5ad8f6403e45b09d3f94ef328891a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/4 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_train = load_dataset(\"huyhoangt2201/fixed_errors_from_contextawareJidouka2\", split='train[:95%]')\n",
    "dataset_val = load_dataset(\"huyhoangt2201/fixed_errors_from_contextawareJidouka2\", split='train[-5%:]')\n",
    "dataset = DatasetDict({\n",
    "    'train': dataset_train,\n",
    "    'validation': dataset_val\n",
    "})\n",
    "dataset.save_to_disk(\"completed_train_dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T14:31:55.574814Z",
     "iopub.status.busy": "2024-12-02T14:31:55.574558Z",
     "iopub.status.idle": "2024-12-02T14:31:55.580270Z",
     "shell.execute_reply": "2024-12-02T14:31:55.579273Z",
     "shell.execute_reply.started": "2024-12-02T14:31:55.574791Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# system_prompt = \"\"\"You are an SQL query assistant. Based on schema and context below, generate an SQL query to retrieve the relevant information for the user. If the user’s question is unrelated to the table, respond naturally in user's language.\n",
    "\n",
    "# Schema:\n",
    "# +Table Author, columns=[AuthorId: int, AuthorName: nvarchar(255), DepartmentId int, GroupDCId int]\n",
    "# +Table Department, columns=[DepartmentId: int, DepartmentName: nvarchar(255)]\n",
    "# +Table GroupDC, columns=[GroupDCId: int, DepartmentId: int, GroupDCName nvarchar(255)]\n",
    "# +Table Job, columns=[JobId: int, JobName: nvarchar(255)]\n",
    "# +Table Tool, columns=[ToolId: int, ToolName: nvarchar(255), ToolDescription: text]\n",
    "# +Table Jidouka, columns=[JidoukaId: bigint, ProductApply: nvarchar(255), ImprovementName: nvarchar(255), SoftwareUsing: nvarchar(255), Description: nvarchar(255), Video: text, DetailDocument: text, TotalJobApplied: int, TotalTimeSaved: int, DateCreate: datetime, JobId: int, AuthorId: int, DepartmentId: int, GroupDCId: int]\n",
    "# +Table JidoukaTool, columns=[JidoukaId: bigint, ToolId: int]\n",
    "# +Primary_keys=[Author.AuthorId, Department.DepartmentId, GroupDC.GroupDCId, Job.JobId, Tool.ToolId, Jidouka.JidoukaId]\n",
    "# +Foreign_keys=[GroupDC.DepartmentId=Department.DepartmentId, Jidouka.JobId=Job.JobId, Jidouka.AuthorId=Author.AuthorId, Jidouka.DepartmentId=Department.DepartmentId, Jidouka.GroupDCId=GroupDC.GroupDCId, JidoukaTool.JidoukaId=Jidouka.JidoukaId, JidoukaTool.ToolId=Tool.ToolId, Author.DepartmentId=Department.DepartmentId, Author.GroupDCId=GroupDC.GroupDCId]\n",
    "\n",
    "# Context:\n",
    "# Previous user question: {previous_question}\n",
    "# Previous answer: {previous_answer}\n",
    "# Previous schema linking(Format: [Tables, Columns, Foreign keys, Possible cell values]): {schema_linking}\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T14:31:55.582442Z",
     "iopub.status.busy": "2024-12-02T14:31:55.581598Z",
     "iopub.status.idle": "2024-12-02T14:31:55.595063Z",
     "shell.execute_reply": "2024-12-02T14:31:55.594163Z",
     "shell.execute_reply.started": "2024-12-02T14:31:55.582384Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# def format_context(sample):\n",
    "#     sample['context'] = system_prompt.format(previous_question=sample['previous_question'], previous_answer=sample['previous_answer'], schema_linking=sample['schema_linking'])\n",
    "    \n",
    "#     return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T03:33:38.758972Z",
     "iopub.status.busy": "2024-12-27T03:33:38.758725Z",
     "iopub.status.idle": "2024-12-27T03:33:38.763496Z",
     "shell.execute_reply": "2024-12-27T03:33:38.762671Z",
     "shell.execute_reply.started": "2024-12-27T03:33:38.758947Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"You are an SQL query assistant. Based on schema, generate an SQL query to retrieve the relevant information for the user. If the user’s question is unrelated to the table, respond naturally in user's language.\n",
    "\n",
    "Schema:\n",
    "+Table Author, columns=[AuthorId: int, AuthorName: nvarchar(255), DepartmentId int, GroupDCId int]\n",
    "+Table Department, columns=[DepartmentId: int, DepartmentName: nvarchar(255)]\n",
    "+Table GroupDC, columns=[GroupDCId: int, DepartmentId: int, GroupDCName nvarchar(255)]\n",
    "+Table Job, columns=[JobId: int, JobName: nvarchar(255)]\n",
    "+Table Tool, columns=[ToolId: int, ToolName: nvarchar(255), ToolDescription: text]\n",
    "+Table Jidouka, columns=[JidoukaId: bigint, ProductApply: nvarchar(255), ImprovementName: nvarchar(255), SoftwareUsing: nvarchar(255), Description: nvarchar(255), Video: text, DetailDocument: text, TotalJobApplied: int, TotalTimeSaved: int, DateCreate: datetime, JobId: int, AuthorId: int, DepartmentId: int, GroupDCId: int]\n",
    "+Table JidoukaTool, columns=[JidoukaId: bigint, ToolId: int]\n",
    "+Primary_keys=[Author.AuthorId, Department.DepartmentId, GroupDC.GroupDCId, Job.JobId, Tool.ToolId, Jidouka.JidoukaId]\n",
    "+Foreign_keys=[GroupDC.DepartmentId=Department.DepartmentId, Jidouka.JobId=Job.JobId, Jidouka.AuthorId=Author.AuthorId, Jidouka.DepartmentId=Department.DepartmentId, Jidouka.GroupDCId=GroupDC.GroupDCId, JidoukaTool.JidoukaId=Jidouka.JidoukaId, JidoukaTool.ToolId=Tool.ToolId, Author.DepartmentId=Department.DepartmentId, Author.GroupDCId=GroupDC.GroupDCId]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T03:33:51.538172Z",
     "iopub.status.busy": "2024-12-27T03:33:51.537831Z",
     "iopub.status.idle": "2024-12-27T03:33:51.542315Z",
     "shell.execute_reply": "2024-12-27T03:33:51.541402Z",
     "shell.execute_reply.started": "2024-12-27T03:33:51.538142Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def format_context(sample):\n",
    "    sample['context'] = system_prompt\n",
    "    \n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T03:34:28.692495Z",
     "iopub.status.busy": "2024-12-27T03:34:28.692146Z",
     "iopub.status.idle": "2024-12-27T03:34:28.742798Z",
     "shell.execute_reply": "2024-12-27T03:34:28.741985Z",
     "shell.execute_reply.started": "2024-12-27T03:34:28.692464Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95e58cf954fc449c82c65af140b19650",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/80 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85ab87fc073942288c86bfae24770318",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_train2 = dataset_train.map(format_context)\n",
    "dataset_val2 = dataset_val.map(format_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T03:34:32.115791Z",
     "iopub.status.busy": "2024-12-27T03:34:32.115084Z",
     "iopub.status.idle": "2024-12-27T03:34:32.121383Z",
     "shell.execute_reply": "2024-12-27T03:34:32.120648Z",
     "shell.execute_reply.started": "2024-12-27T03:34:32.115757Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['previous_question', 'previous_answer', 'schema_linking', 'question', 'answer', 'context'],\n",
       "    num_rows: 80\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T03:34:41.679888Z",
     "iopub.status.busy": "2024-12-27T03:34:41.679158Z",
     "iopub.status.idle": "2024-12-27T03:34:41.691974Z",
     "shell.execute_reply": "2024-12-27T03:34:41.691255Z",
     "shell.execute_reply.started": "2024-12-27T03:34:41.679854Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset_train3 = dataset_train2.shuffle(seed=42)\n",
    "dataset_val3 = dataset_val2.shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T03:35:23.857366Z",
     "iopub.status.busy": "2024-12-27T03:35:23.857041Z",
     "iopub.status.idle": "2024-12-27T03:35:23.862201Z",
     "shell.execute_reply": "2024-12-27T03:35:23.861275Z",
     "shell.execute_reply.started": "2024-12-27T03:35:23.857320Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def format_data_template(sample):\n",
    "    chat = [\n",
    "          {\"role\":\"system\", \"content\": sample['context']},\n",
    "          {\"role\":\"user\", \"content\":sample['previous_question']},\n",
    "          {\"role\":\"assistant\",\"content\":sample['previous_answer']}\n",
    "    ]\n",
    "    return {\n",
    "        \"messages\": tokenizer.apply_chat_template(chat, tokenize=False, add_generation_prompt=True)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T03:35:26.572833Z",
     "iopub.status.busy": "2024-12-27T03:35:26.572204Z",
     "iopub.status.idle": "2024-12-27T03:35:26.949416Z",
     "shell.execute_reply": "2024-12-27T03:35:26.948537Z",
     "shell.execute_reply.started": "2024-12-27T03:35:26.572798Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "649e1c65632e4509b3bb4008848f50d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/80 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc7cdae013234c62994c4f0a8989ad4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_set = dataset_train3.map(format_data_template, remove_columns=['context','question','answer','previous_question', 'previous_answer','schema_linking'])\n",
    "val_set = dataset_val3.map(format_data_template, remove_columns=['context','question','answer','previous_question', 'previous_answer','schema_linking'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T03:35:29.926660Z",
     "iopub.status.busy": "2024-12-27T03:35:29.926286Z",
     "iopub.status.idle": "2024-12-27T03:35:29.932807Z",
     "shell.execute_reply": "2024-12-27T03:35:29.931956Z",
     "shell.execute_reply.started": "2024-12-27T03:35:29.926627Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 27 Dec 2024\\n\\nYou are an SQL query assistant. Based on schema, generate an SQL query to retrieve the relevant information for the user. If the user’s question is unrelated to the table, respond naturally in user's language.\\n\\nSchema:\\n+Table Author, columns=[AuthorId: int, AuthorName: nvarchar(255), DepartmentId int, GroupDCId int]\\n+Table Department, columns=[DepartmentId: int, DepartmentName: nvarchar(255)]\\n+Table GroupDC, columns=[GroupDCId: int, DepartmentId: int, GroupDCName nvarchar(255)]\\n+Table Job, columns=[JobId: int, JobName: nvarchar(255)]\\n+Table Tool, columns=[ToolId: int, ToolName: nvarchar(255), ToolDescription: text]\\n+Table Jidouka, columns=[JidoukaId: bigint, ProductApply: nvarchar(255), ImprovementName: nvarchar(255), SoftwareUsing: nvarchar(255), Description: nvarchar(255), Video: text, DetailDocument: text, TotalJobApplied: int, TotalTimeSaved: int, DateCreate: datetime, JobId: int, AuthorId: int, DepartmentId: int, GroupDCId: int]\\n+Table JidoukaTool, columns=[JidoukaId: bigint, ToolId: int]\\n+Primary_keys=[Author.AuthorId, Department.DepartmentId, GroupDC.GroupDCId, Job.JobId, Tool.ToolId, Jidouka.JidoukaId]\\n+Foreign_keys=[GroupDC.DepartmentId=Department.DepartmentId, Jidouka.JobId=Job.JobId, Jidouka.AuthorId=Author.AuthorId, Jidouka.DepartmentId=Department.DepartmentId, Jidouka.GroupDCId=GroupDC.GroupDCId, JidoukaTool.JidoukaId=Jidouka.JidoukaId, JidoukaTool.ToolId=Tool.ToolId, Author.DepartmentId=Department.DepartmentId, Author.GroupDCId=GroupDC.GroupDCId]<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nDanh sách các nhóm trong DC4 đã thực hiện cải tiến với công cụ CAD?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nSELECT DISTINCT GroupDC.GroupDCName FROM GroupDC JOIN Jidouka ON GroupDC.GroupDCId = Jidouka.GroupDCId JOIN Department ON Jidouka.DepartmentId = Department.DepartmentId JOIN JidoukaTool ON Jidouka.JidoukaId = JidoukaTool.JidoukaId JOIN Tool ON JidoukaTool.ToolId = Tool.ToolId WHERE Department.DepartmentName LIKE LOWER('%DC4%') AND Tool.ToolName LIKE LOWER('%CAD%');<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set['messages'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# training_arguments = TrainingArguments(\n",
    "#     output_dir=new_model,\n",
    "#     per_device_train_batch_size=2,\n",
    "#     per_device_eval_batch_size=2,\n",
    "#     gradient_accumulation_steps=4,\n",
    "#     optim=\"adamw_8bit\",\n",
    "#     num_train_epochs=25,\n",
    "#     eval_strategy=\"epoch\",\n",
    "#     eval_steps=0.2,\n",
    "#     save_strategy='epoch',\n",
    "#     logging_steps=1,\n",
    "#     warmup_steps=10,\n",
    "#     logging_strategy=\"steps\",\n",
    "#     learning_rate=2e-4,\n",
    "#     fp16=False,\n",
    "#     bf16=True,\n",
    "#     group_by_length=True,\n",
    "#     report_to=\"wandb\",\n",
    "#     load_best_model_at_end = True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T03:53:45.342702Z",
     "iopub.status.busy": "2024-12-27T03:53:45.341928Z",
     "iopub.status.idle": "2024-12-27T03:53:45.384316Z",
     "shell.execute_reply": "2024-12-27T03:53:45.383699Z",
     "shell.execute_reply.started": "2024-12-27T03:53:45.342667Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "early_stopping_callback = EarlyStoppingCallback( \n",
    "    early_stopping_patience=5\n",
    ")\n",
    "\n",
    "sft_config = SFTConfig(\n",
    "    output_dir=new_model,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    optim=\"adamw_8bit\",\n",
    "    num_train_epochs=25,\n",
    "    eval_strategy=\"epoch\",\n",
    "    eval_steps=0.2,\n",
    "    dataset_text_field = 'messages',\n",
    "    max_seq_length = 2048, \n",
    "    save_strategy='epoch',\n",
    "    logging_steps=1,\n",
    "    warmup_steps=10,\n",
    "    logging_strategy=\"steps\",\n",
    "    learning_rate=2e-4,\n",
    "    fp16=False,\n",
    "    bf16=True,\n",
    "    group_by_length=True,\n",
    "    #report_to=\"wandb\",\n",
    "    packing = False,\n",
    "    load_best_model_at_end = True\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T03:53:48.064880Z",
     "iopub.status.busy": "2024-12-27T03:53:48.064177Z",
     "iopub.status.idle": "2024-12-27T03:53:48.546885Z",
     "shell.execute_reply": "2024-12-27T03:53:48.545524Z",
     "shell.execute_reply.started": "2024-12-27T03:53:48.064846Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30/3182841344.py:1: FutureWarning: `tokenizer` is deprecated and removed starting from version 0.16.0 for `SFTTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = SFTTrainer(\n"
     ]
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = train_set,\n",
    "    eval_dataset = val_set,\n",
    "    args = sft_config,\n",
    "    peft_config = peft_config, \n",
    "    callbacks=[early_stopping_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T03:53:51.347840Z",
     "iopub.status.busy": "2024-12-27T03:53:51.347437Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m API key must be 40 characters long, yours was 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a25855b95532442c98752adcc1db0540",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112713744442873, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20241227_035638-d9rl1b3x</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/huyhoangt2201-fpt-university/huggingface/runs/d9rl1b3x' target=\"_blank\">llama-3.2-1b-sql_finetuned_multitableJidouka2_1.0_977_records_mix_fix_84_records</a></strong> to <a href='https://wandb.ai/huyhoangt2201-fpt-university/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/huyhoangt2201-fpt-university/huggingface' target=\"_blank\">https://wandb.ai/huyhoangt2201-fpt-university/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/huyhoangt2201-fpt-university/huggingface/runs/d9rl1b3x' target=\"_blank\">https://wandb.ai/huyhoangt2201-fpt-university/huggingface/runs/d9rl1b3x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 56/250 12:36 < 45:17, 0.07 it/s, Epoch 5.50/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.048100</td>\n",
       "      <td>0.040687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.019900</td>\n",
       "      <td>0.024582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.014300</td>\n",
       "      <td>0.017012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.016700</td>\n",
       "      <td>0.013846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.013300</td>\n",
       "      <td>0.013730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "eot = \"<|eot_id|>\"\n",
    "eot_id = tokenizer.convert_tokens_to_ids(eot)\n",
    "tokenizer.pad_token = eot\n",
    "tokenizer.pad_token_id = eot_id\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T15:06:19.610831Z",
     "iopub.status.busy": "2024-12-02T15:06:19.610508Z",
     "iopub.status.idle": "2024-12-02T15:06:19.617242Z",
     "shell.execute_reply": "2024-12-02T15:06:19.616525Z",
     "shell.execute_reply.started": "2024-12-02T15:06:19.610805Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'llama-3.2-1b-sql_finetuned_multitableJidouka2_1.0_977_records_mix_fix_84_records_adapter'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adapter_model = new_model+'_adapter'\n",
    "adapter_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T15:06:22.403146Z",
     "iopub.status.busy": "2024-12-02T15:06:22.402747Z",
     "iopub.status.idle": "2024-12-02T15:06:25.957371Z",
     "shell.execute_reply": "2024-12-02T15:06:25.956655Z",
     "shell.execute_reply.started": "2024-12-02T15:06:22.403106Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d64ba74ac7e042babe5ee9b18eb6d952",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/45.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/huyhoangt2201/llama-3.2-1b-sql_finetuned_multitableJidouka2_1.0_977_records_mix_fix_84_records_adapter/commit/009fd87f2bf7ac9699982f7d9351d3be7bb8ec6c', commit_message='Upload model', commit_description='', oid='009fd87f2bf7ac9699982f7d9351d3be7bb8ec6c', pr_url=None, repo_url=RepoUrl('https://huggingface.co/huyhoangt2201/llama-3.2-1b-sql_finetuned_multitableJidouka2_1.0_977_records_mix_fix_84_records_adapter', endpoint='https://huggingface.co', repo_type='model', repo_id='huyhoangt2201/llama-3.2-1b-sql_finetuned_multitableJidouka2_1.0_977_records_mix_fix_84_records_adapter'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.model.save_pretrained(adapter_model)\n",
    "trainer.model.push_to_hub(adapter_model, use_temp_dir=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T15:06:33.275587Z",
     "iopub.status.busy": "2024-12-02T15:06:33.274650Z",
     "iopub.status.idle": "2024-12-02T15:06:33.280086Z",
     "shell.execute_reply": "2024-12-02T15:06:33.279250Z",
     "shell.execute_reply.started": "2024-12-02T15:06:33.275550Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "adapter_model = 'huyhoangt2201/' + adapter_model\n",
    "base_model = 'huyhoangt2201/llama-3.2-1b-sql_finetuned_multitableJidouka2_1.0_977_records_mix_fix_210_records_merged'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T04:14:23.603028Z",
     "iopub.status.busy": "2024-12-04T04:14:23.602688Z",
     "iopub.status.idle": "2024-12-04T04:15:29.980305Z",
     "shell.execute_reply": "2024-12-04T04:15:29.979582Z",
     "shell.execute_reply.started": "2024-12-04T04:14:23.603000Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "363de388a52a437f98575479b7e6850a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/54.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "044821e3ab1247c69981e0e20f38b047",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f09a5418cf6a424885adff69e594cfcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f34b0953aec4174803af25b0ced6c3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/877 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cea103db20424de1b38c498eb96e06ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.47G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3dc0d95dcef4dadaf360bbf892fbbf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d8a10afe1ba4c7da53136d45cb862a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_config.json:   0%|          | 0.00/805 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "947ac51b5a0947739ab48c3cc5e91665",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/45.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
    "\n",
    "base_model_reload = AutoModelForCausalLM.from_pretrained(\n",
    "        base_model,\n",
    "        return_dict=True,\n",
    "        low_cpu_mem_usage=True,\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=\"auto\",\n",
    "        trust_remote_code=True,\n",
    ")\n",
    "\n",
    "# base_model_reload, tokenizer = setup_chat_format(base_model_reload, tokenizer)\n",
    "\n",
    "# Merge adapter with base model\n",
    "merge_model = PeftModel.from_pretrained(base_model_reload, adapter_model)\n",
    "\n",
    "merge_model = merge_model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T15:06:43.334732Z",
     "iopub.status.busy": "2024-12-02T15:06:43.334346Z",
     "iopub.status.idle": "2024-12-02T15:06:49.944202Z",
     "shell.execute_reply": "2024-12-02T15:06:49.943198Z",
     "shell.execute_reply.started": "2024-12-02T15:06:43.334702Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('llama-3.2-1b-sql_finetuned_multitableJidouka2_1.0_977_records_mix_fix_84_records_merged/tokenizer_config.json',\n",
       " 'llama-3.2-1b-sql_finetuned_multitableJidouka2_1.0_977_records_mix_fix_84_records_merged/special_tokens_map.json',\n",
       " 'llama-3.2-1b-sql_finetuned_multitableJidouka2_1.0_977_records_mix_fix_84_records_merged/tokenizer.json')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_model = new_model + '_merged'\n",
    "merge_model.save_pretrained(merged_model)\n",
    "tokenizer.save_pretrained(merged_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T15:06:49.946000Z",
     "iopub.status.busy": "2024-12-02T15:06:49.945726Z",
     "iopub.status.idle": "2024-12-02T15:06:50.110708Z",
     "shell.execute_reply": "2024-12-02T15:06:50.109891Z",
     "shell.execute_reply.started": "2024-12-02T15:06:49.945974Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "user_secrets = UserSecretsClient()\n",
    "\n",
    "hf_token = user_secrets.get_secret(\"HF_TOKEN\")\n",
    "login(token = hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T04:16:31.850095Z",
     "iopub.status.busy": "2024-12-04T04:16:31.849722Z",
     "iopub.status.idle": "2024-12-04T04:17:50.142957Z",
     "shell.execute_reply": "2024-12-04T04:17:50.142267Z",
     "shell.execute_reply.started": "2024-12-04T04:16:31.850063Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aab49a836db46f4a38721f9fa63504b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.47G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4261ef026e246eca9d430b5c7d0575b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60454ac03ef2470d92cce9e66da35e72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/huyhoangt2201/Llama-3.2-1B-Instruct-Frog_fixed_84errors_merged/commit/540e4241b140ffa563ac5b615336e82417d62f08', commit_message='Upload tokenizer', commit_description='', oid='540e4241b140ffa563ac5b615336e82417d62f08', pr_url=None, repo_url=RepoUrl('https://huggingface.co/huyhoangt2201/Llama-3.2-1B-Instruct-Frog_fixed_84errors_merged', endpoint='https://huggingface.co', repo_type='model', repo_id='huyhoangt2201/Llama-3.2-1B-Instruct-Frog_fixed_84errors_merged'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_model.push_to_hub(merged_model, use_temp_dir=False)\n",
    "tokenizer.push_to_hub(merged_model, use_temp_dir=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
